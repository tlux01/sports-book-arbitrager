def url_scraper():
    url = 'https://www.sportsplays.com/make-pick.html'

    # sportsbook ncaa basketball
    # url = 'https://www.sportsbook.com/sbk/sportsbook4/ncaa-football-betting/game-lines.sbk'
    s = requests.session()

    login_data = {
        'username' : '',
        'password': '',
    }
    response = s.post(url, data=login_data)
    r = s.get('https://www.sportsplays.com/make-pick.html')
    soup = BeautifulSoup(r.content, 'html.parser')
    #locates tab with urls and pulls them
    sports_tabs = soup.find(id = 'sports_tabs')
    anchor_tags = sports_tabs.findAll('a')
    num_anchors = len(anchor_tags)

    url_first_piece = 'https://www.sportsplays.com'
    url_last_peice_game = ''
    url_last_peice_first_half = '/pick_type/first_half.html'
    url_last_peice_first_quarter = '/pick_type/first_quarter.html'
    url_last_peice_second_half = '/pick_type/second_half.html'
    x = 0
    url_list_of_sec = []
    final_link_list = []
    i=0
    #creates a list of the second piece of urls
    while x < num_anchors:
        url_second_piece = anchor_tags[x].get('href')
        url_list_of_sec.append(url_second_piece[:-5])
        x+=1

    while i < len(url_list_of_sec):
        final_link = url_first_piece + url_list_of_sec[i] + url_last_peice_game
        final_link_list.append(final_link)
        final_link = url_first_piece + url_list_of_sec[i] + url_last_peice_first_half
        final_link_list.append(final_link)
        final_link = url_first_piece + url_list_of_sec[i] + url_last_peice_first_quarter
        final_link_list.append(final_link)
        final_link = url_first_piece + url_list_of_sec[i] + url_last_peice_second_half
        final_link_list.append(final_link)
        i += 1

    print(final_link_list)
